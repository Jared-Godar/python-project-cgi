{"cells":[{"cell_type":"markdown","source":["#### Data Engineering Exercise 1: Pandas \nThe Parking Citation Dataset is a puplic dataset collecting millions of records information about parking tickets for a county in California. We only selected a million of this data for us to work with in this assignment. You can see the whole dataset here: https://data.lacity.org/Transportation/Parking-Citations/wjz9-h9np/data\n\nIn this exercise we want you to Extract data, Transform and/or clean data, and then Save it as a new file. Steps are:\n\n    1. Extract CSV and Json file and append these files into a Pandas DataFrame.\n    2. Remove the spaces from column headers\n    3. Change data types\n    4. Check if a column has any digits in its values\n    5. Write a function to check if a column only has \"Alphabet\" values\n    6. Write a function to check if a column only has \"Numberic\" values\n    7. Add a column \"Distance_to_pointA\", calculating the distance between each point and point A\n    8. Handle duplicates\n    9. Drop columns with 70% missing values\n    10. Remove a few records based on a condition \n    11. Fill missing values for a column\n    12. Split a column into severl coulmns \n    13. Extract the \"Issue_year\" of  \"Issue_Date\" column and save it as a new column \"Issue_year\" as an integer type.\n    14. Save the final modified dataframe into a partitioned parquet file! If you are not able to save it as a parquet file, go ahead and save it as a csv file. \n\n\nHere are some resources that you may need: \n\n    Pandas =  https://pandas.pydata.org/docs/reference/general_functions.html\n    Numpy = https://numpy.org/doc/stable/reference/index.html\n\n\nGood luck!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"352229ec-beaa-47b1-b249-3ccff25aa3c9"}}},{"cell_type":"markdown","source":["##### IMPORTS"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"10ef76be-0792-4474-8be3-1c0daa8e6cfb"}}},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d876999-8232-453c-8a50-31a7d45205c1"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### 1. Complete the below function to Extract CSV and Json file and Append these file to a Pandas DataFrame:\n- csv file: parking_citation_sample.csv\n- Json file: parking_citation_add.json"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"abc4822f-3841-46ab-bf27-2182959ab1d9"}}},{"cell_type":"code","source":["df_pandas = pd.DataFrame(\n    columns=['Ticket number', 'Issue Date', 'Issue time', 'Meter Id', 'Marked Time',\n   'RP State Plate', 'Plate Expiry Date', 'VIN', 'Make', 'Body Style',\n   'Color', 'Location', 'Route', 'Agency', 'Violation code',\n   'Violation Description', 'Fine amount', 'Latitude', 'Longitude',\n   'Agency Description', 'Color Description', 'Body Style Description'])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e88c229-c249-450c-b062-623724130474"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["##read the shared folder data into spark dataframe\ndf0 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_0.csv')\ndf1 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_1.csv')\ndf2 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_2.csv')\ndf3 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_3.csv')\ndf4 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_4.csv')\ndf_csv = pd.concat([df0, df1,df2,df3,df4])\n# Drop the first column, and append it to pandas dataframe\ndf_csv = df_csv.iloc[: , 1:]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9da7ccfa-a06e-4aae-a846-2be9aba7eb9b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/databricks/python/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["/databricks/python/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"]}}],"execution_count":0},{"cell_type":"code","source":["df_pandas"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a5fb0a2b-782c-401b-9fb0-8872c8f05570"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ticket number</th>\n      <th>Issue Date</th>\n      <th>Issue time</th>\n      <th>Meter Id</th>\n      <th>Marked Time</th>\n      <th>RP State Plate</th>\n      <th>Plate Expiry Date</th>\n      <th>VIN</th>\n      <th>Make</th>\n      <th>Body Style</th>\n      <th>...</th>\n      <th>Route</th>\n      <th>Agency</th>\n      <th>Violation code</th>\n      <th>Violation Description</th>\n      <th>Fine amount</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Agency Description</th>\n      <th>Color Description</th>\n      <th>Body Style Description</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows × 22 columns</p>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ticket number</th>\n      <th>Issue Date</th>\n      <th>Issue time</th>\n      <th>Meter Id</th>\n      <th>Marked Time</th>\n      <th>RP State Plate</th>\n      <th>Plate Expiry Date</th>\n      <th>VIN</th>\n      <th>Make</th>\n      <th>Body Style</th>\n      <th>...</th>\n      <th>Route</th>\n      <th>Agency</th>\n      <th>Violation code</th>\n      <th>Violation Description</th>\n      <th>Fine amount</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Agency Description</th>\n      <th>Color Description</th>\n      <th>Body Style Description</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows × 22 columns</p>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["df_pandas.shape"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9bab08c9-100b-498e-8afd-31a9c4ab704f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[12]: (0, 22)","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[12]: (0, 22)"]}}],"execution_count":0},{"cell_type":"code","source":["df_csv.shape"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"351d1621-a71f-4f3d-95cf-bc8efafe5317"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[11]: (833311, 23)","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[11]: (833311, 23)"]}}],"execution_count":0},{"cell_type":"code","source":["#Append\ndf_pandas = df_pandas.append(df_csv)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5402562-2d78-4763-b179-b6a042beefc1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_pandas.shape"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"540bcc95-f78b-4ea4-a447-cc8c132ecaa3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[14]: (833311, 23)","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[14]: (833311, 23)"]}}],"execution_count":0},{"cell_type":"code","source":["print(type(df_csv))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d5ef988a-f9e4-414b-a70f-7d956bb635ff"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<class 'pandas.core.frame.DataFrame'>\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["<class 'pandas.core.frame.DataFrame'>\n"]}}],"execution_count":0},{"cell_type":"code","source":["def extract_data():\n    df_pandas = pd.DataFrame(\n        columns=['Ticket number', 'Issue Date', 'Issue time', 'Meter Id', 'Marked Time',\n       'RP State Plate', 'Plate Expiry Date', 'VIN', 'Make', 'Body Style',\n       'Color', 'Location', 'Route', 'Agency', 'Violation code',\n       'Violation Description', 'Fine amount', 'Latitude', 'Longitude',\n       'Agency Description', 'Color Description', 'Body Style Description'])\n    \n    ##read the shared folder data into spark dataframe\n    df0 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_0.csv')\n    df1 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_1.csv')\n    df2 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_2.csv')\n    df3 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_3.csv')\n    df4 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_4.csv')\n    df_csv = pd.concat([df0, df1,df2,df3,df4])\n    # Drop the first column, and append it to pandas dataframe\n    df_csv = df_csv.iloc[: , 1:]\n    df_pandas = df_pandas.append(df_csv)\n\n    # read and append json\n\n    df_json = pd.read_json('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_add.json')\n    df_json = df_json.iloc[: , 1:]\n    df_pandas = df_pandas.append(df_json)\n    \n    df_pandas = df_pandas.replace('', np.nan)\n        \n    return df_pandas\n\ndf_pandas = extract_data()\nprint('Shape of Data: '+ str(df_pandas.shape))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0239d3cc-c2ff-45bb-a87c-3e6219a97414"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/databricks/python/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n  if (await self.run_code(code, result,  async_=asy)):\nShape of Data: (833341, 23)\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["/databricks/python/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n  if (await self.run_code(code, result,  async_=asy)):\nShape of Data: (833341, 23)\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### 2. Remove the spaces from column headers and replace it with underline:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e3bf2430-cde6-4b18-a31c-56c2eb82473f"}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b314c953-4c5a-47d3-b784-b18337eccc23"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### 3. Change data types for (Ticket_number, Issue_Date ) columns into (string, datetime) respectively"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6628b023-dac9-42f5-b173-ac6a39f021fd"}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0acf693e-00d4-4179-a42d-287a8bd71590"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### 4. Check if a column has any digits in its values. Return the rows where this is true. Check for column \"Violation_Description\". \ne.g. 17104h --> True,     WHITE CURB --> False"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1ee22dfd-05ab-4a2b-8841-165965158354"}}},{"cell_type":"code","source":["my_col = 'Violation_Description'\n\ndef has_digit(df, my_col):\n    \n    *** WRITE YOUR CODE TO complete the function ***\n    \n    return \n\nhas_digit(df_pandas, my_col)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c7a6c77-702a-49fa-b8b6-103fb749af6c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### 5. Write a function to check if a column only has \"Alphabet\" values, return the rows where this is not true. Check for \"Make\" column."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6222d006-ef6f-46c1-b24e-5fb331d77731"}}},{"cell_type":"code","source":["my_col = 'Make'\n\ndef only_alpha(df, my_col):\n    \n    *** WRITE YOUR CODE TO complete the function ***\n    \n    return \n\nonly_alpha(df_pandas, my_col)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9fff9512-f73d-4060-9f33-421f71a22c4a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### 6. Write a function to check if a column only has \"Numberic\" values, return the rows where this is not true. Check for TicketNumber column."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4c0c9ba4-4cd4-421d-9cef-5bde72990866"}}},{"cell_type":"code","source":["my_col = 'Ticket_number'\n\ndef only_number(df, my_col):\n    \n    *** WRITE YOUR CODE TO complete the function ***\n    \n    return \n\nonly_number(df_pandas, my_col)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"62c7b641-1f9d-426a-ba90-875581f34921"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### 7. Add a column \"Distance_to_pointA\", collecting the distance between each point and the point A: Ya= 6439997, Xa= 1802686. \nDrop rows with either Nan or values like 99999. \n\nNote: Parking citations with latitude / longitude (XY) in US Feet coordinates according to the NAD_1983_StatePlane_California_V_FIPS_0405_Feet projection."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2db6c35d-cfc8-486f-8f41-65a2f49d042a"}}},{"cell_type":"code","source":["# drop rows with values like 99999 in Latitude and/or Longitude\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5bec144-bb95-4b6b-be93-aa2aff025b2c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# calculate distance between all rows(Longitude/Latitude) and point A (6439997,1802686)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"df243201-cac8-47d2-a012-f5d70ac961e5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### 8. Is there any duplicates in dataframe? If yes, print them and then drop them."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"77b64cff-1e9c-4150-abd1-82d4363fff05"}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9ad0de0d-1d8b-42aa-a774-f9f982aedd04"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### 9. Find the columns with more than 70% missing values, print them, and then drop them."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f8a5f9f-b9d5-4208-bad9-7ede1d8fc4a7"}}},{"cell_type":"code","source":["# Find the columns with more than 70% missing values\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4f73bc16-7a83-49b1-9ab3-d1295733c530"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Drop columns with more than 70% missing values \n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4f2c0343-c724-4845-a38e-ddd6b8d2ae04"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### 10. Find RP_State_Plates that are not for US, then drop their data."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2fba1e93-9fe4-49c7-8871-27bd0cc3a04f"}}},{"cell_type":"code","source":["# To find the US state abbrevation, you can use State_Abbreviation.xlsx' dataset\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"65a584aa-d828-41be-8208-2089d3dd5798"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### 11. Almost 4% of Fine_Amount column has missing values, handle these missing values."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8cb7c587-5aea-4d2b-8678-4b7731fe97a8"}}},{"cell_type":"code","source":["# Use your knowledge to handle the missing values, you need to impute values based on useful information of other columns \n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"86c00653-5883-4c98-bb35-8877fec43228"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### 12. Split the \"Location\" column into new columns using SPACE as delimiter. You may need to write a function. The final splitted data should be structured like below (the number of columns may be different):\n![address_columns.PNG](attachment:address_columns.PNG)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c86273d1-392d-4da7-9ac8-ddc7339e7a32"}}},{"cell_type":"code","source":["def address_sep(df_pandas):\n \n    *** WRITE YOUR CODE TO complete the function ***\n    return df_pandas\n\ndf_pandas = address_sep(df_pandas)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d936b40d-3f1b-480c-9d18-ce1301a3d987"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### 13. Extract the \"Issue_year\" of  \"Issue_Date\" column and save it as a new column \"Issue_year\" as an integer type."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"181ba8dd-fb02-4540-96c4-14589fb8f8ed"}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5d0a0132-fe94-4645-8551-4916ca93a8bf"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### 14. Write the pandas dataframe into a Parquet file (cleaned_parking_citations) partition by \"Year\" column."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"277e2217-179b-4ae8-9d06-9e79449c4f1d"}}},{"cell_type":"code","source":["df_pandas.to_parquet(*** WRITE YOUR CODE TO complete the function ***)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c9b7758c-7a68-4f4a-8e37-1b045a30859e"}},"outputs":[],"execution_count":0}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.8.8","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"Data_Engineering_Exercise_1","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2073302174308515}},"nbformat":4,"nbformat_minor":0}

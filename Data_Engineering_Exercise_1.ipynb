{"cells":[{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"352229ec-beaa-47b1-b249-3ccff25aa3c9","showTitle":false,"title":""}},"source":["#### Data Engineering Exercise 1: Pandas \n","The Parking Citation Dataset is a puplic dataset collecting millions of records information about parking tickets for a county in California. We only selected a million of this data for us to work with in this assignment. You can see the whole dataset here: https://data.lacity.org/Transportation/Parking-Citations/wjz9-h9np/data\n","\n","In this exercise we want you to Extract data, Transform and/or clean data, and then Save it as a new file. Steps are:\n","\n","    1. Extract CSV and Json file and append these files into a Pandas DataFrame.\n","    2. Remove the spaces from column headers\n","    3. Change data types\n","    4. Check if a column has any digits in its values\n","    5. Write a function to check if a column only has \"Alphabet\" values\n","    6. Write a function to check if a column only has \"Numberic\" values\n","    7. Add a column \"Distance_to_pointA\", calculating the distance between each point and point A\n","    8. Handle duplicates\n","    9. Drop columns with 70% missing values\n","    10. Remove a few records based on a condition \n","    11. Fill missing values for a column\n","    12. Split a column into severl coulmns \n","    13. Extract the \"Issue_year\" of  \"Issue_Date\" column and save it as a new column \"Issue_year\" as an integer type.\n","    14. Save the final modified dataframe into a partitioned parquet file! If you are not able to save it as a parquet file, go ahead and save it as a csv file. \n","\n","\n","Here are some resources that you may need: \n","\n","    Pandas =  https://pandas.pydata.org/docs/reference/general_functions.html\n","    Numpy = https://numpy.org/doc/stable/reference/index.html\n","\n","\n","Good luck!"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"10ef76be-0792-4474-8be3-1c0daa8e6cfb","showTitle":false,"title":""}},"source":["##### IMPORTS"]},{"cell_type":"code","execution_count":27,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"8d876999-8232-453c-8a50-31a7d45205c1","showTitle":false,"title":""}},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"abc4822f-3841-46ab-bf27-2182959ab1d9","showTitle":false,"title":""}},"source":["##### 1. Complete the below function to Extract CSV and Json file and Append these file to a Pandas DataFrame:\n","- csv file: parking_citation_sample.csv\n","- Json file: parking_citation_add.json"]},{"cell_type":"code","execution_count":28,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"5e88c229-c249-450c-b062-623724130474","showTitle":false,"title":""}},"outputs":[],"source":["df_pandas = pd.DataFrame(\n","    columns=['Ticket number', 'Issue Date', 'Issue time', 'Meter Id', 'Marked Time',\n","   'RP State Plate', 'Plate Expiry Date', 'VIN', 'Make', 'Body Style',\n","   'Color', 'Location', 'Route', 'Agency', 'Violation code',\n","   'Violation Description', 'Fine amount', 'Latitude', 'Longitude',\n","   'Agency Description', 'Color Description', 'Body Style Description'])"]},{"cell_type":"code","execution_count":31,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9da7ccfa-a06e-4aae-a846-2be9aba7eb9b","showTitle":false,"title":""}},"outputs":[],"source":["##read the shared folder data into spark dataframe\n","df0 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_0.csv')\n","df1 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_1.csv')\n","df2 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_2.csv')\n","df3 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_3.csv')\n","df4 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_4.csv')\n","df_csv = pd.concat([df0, df1,df2,df3,df4])\n","# Drop the first column, and append it to pandas dataframe\n","df_csv = df_csv.iloc[: , 1:]"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"a5fb0a2b-782c-401b-9fb0-8872c8f05570","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Ticket number</th>\n","      <th>Issue Date</th>\n","      <th>Issue time</th>\n","      <th>Meter Id</th>\n","      <th>Marked Time</th>\n","      <th>RP State Plate</th>\n","      <th>Plate Expiry Date</th>\n","      <th>VIN</th>\n","      <th>Make</th>\n","      <th>Body Style</th>\n","      <th>...</th>\n","      <th>Route</th>\n","      <th>Agency</th>\n","      <th>Violation code</th>\n","      <th>Violation Description</th>\n","      <th>Fine amount</th>\n","      <th>Latitude</th>\n","      <th>Longitude</th>\n","      <th>Agency Description</th>\n","      <th>Color Description</th>\n","      <th>Body Style Description</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","<p>0 rows × 22 columns</p>\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Ticket number</th>\n      <th>Issue Date</th>\n      <th>Issue time</th>\n      <th>Meter Id</th>\n      <th>Marked Time</th>\n      <th>RP State Plate</th>\n      <th>Plate Expiry Date</th>\n      <th>VIN</th>\n      <th>Make</th>\n      <th>Body Style</th>\n      <th>...</th>\n      <th>Route</th>\n      <th>Agency</th>\n      <th>Violation code</th>\n      <th>Violation Description</th>\n      <th>Fine amount</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Agency Description</th>\n      <th>Color Description</th>\n      <th>Body Style Description</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n<p>0 rows × 22 columns</p>\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"textData":null,"type":"htmlSandbox"}},"output_type":"display_data"}],"source":["df_pandas"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9bab08c9-100b-498e-8afd-31a9c4ab704f","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["Out[12]: (0, 22)"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"Out[12]: (0, 22)","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["df_pandas.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"351d1621-a71f-4f3d-95cf-bc8efafe5317","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["Out[11]: (833311, 23)"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"Out[11]: (833311, 23)","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["df_csv.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"f5402562-2d78-4763-b179-b6a042beefc1","showTitle":false,"title":""}},"outputs":[],"source":["#Append\n","df_pandas = df_pandas.append(df_csv)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"540bcc95-f78b-4ea4-a447-cc8c132ecaa3","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["Out[14]: (833311, 23)"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"Out[14]: (833311, 23)","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["df_pandas.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d5ef988a-f9e4-414b-a70f-7d956bb635ff","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["<class 'pandas.core.frame.DataFrame'>\n"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<class 'pandas.core.frame.DataFrame'>\n","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"ansi"}},"output_type":"display_data"}],"source":["print(type(df_csv))"]},{"cell_type":"code","execution_count":39,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"0239d3cc-c2ff-45bb-a87c-3e6219a97414","showTitle":false,"title":""}},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\JARED~1.GOD\\AppData\\Local\\Temp/ipykernel_29612/708241215.py:30: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n","  df_pandas = extract_data()\n"]},{"name":"stdout","output_type":"stream","text":["Shape of Data: (833341, 23)\n"]}],"source":["def extract_data():\n","    df_pandas = pd.DataFrame(\n","        columns=['Ticket number', 'Issue Date', 'Issue time', 'Meter Id', 'Marked Time',\n","       'RP State Plate', 'Plate Expiry Date', 'VIN', 'Make', 'Body Style',\n","       'Color', 'Location', 'Route', 'Agency', 'Violation code',\n","       'Violation Description', 'Fine amount', 'Latitude', 'Longitude',\n","       'Agency Description', 'Color Description', 'Body Style Description'])\n","    \n","    ##read the shared folder data into spark dataframe\n","    df0 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_0.csv')\n","    df1 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_1.csv')\n","    df2 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_2.csv')\n","    df3 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_3.csv')\n","    df4 = pd.read_csv('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_sample_4.csv')\n","    df_csv = pd.concat([df0, df1,df2,df3,df4])\n","    # Drop the first column, and append it to pandas dataframe\n","    df_csv = df_csv.iloc[: , 1:]\n","    df_pandas = df_pandas.append(df_csv)\n","\n","    # read and append json\n","\n","    df_json = pd.read_json('https://raw.githubusercontent.com/matthewbrennerCGI/Project1Data/main/parking_citation_add.json')\n","    df_json = df_json.iloc[: , 1:]\n","    df_pandas = df_pandas.append(df_json)\n","    \n","    df_pandas = df_pandas.replace('', np.nan)\n","        \n","    return df_pandas\n","\n","df_pandas = extract_data()\n","print('Shape of Data: '+ str(df_pandas.shape))"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"e3bf2430-cde6-4b18-a31c-56c2eb82473f","showTitle":false,"title":""}},"source":["##### 2. Remove the spaces from column headers and replace it with underline:"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Make a copy to work with\n","df=df_pandas.copy()"]},{"cell_type":"code","execution_count":4,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b314c953-4c5a-47d3-b784-b18337eccc23","showTitle":false,"title":""}},"outputs":[],"source":["# remove spaces in columns name\n","df.columns = df.columns.str.replace(' ','_')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Ticket_number</th>\n","      <th>Issue_Date</th>\n","      <th>Issue_time</th>\n","      <th>Meter_Id</th>\n","      <th>Marked_Time</th>\n","      <th>RP_State_Plate</th>\n","      <th>Plate_Expiry_Date</th>\n","      <th>VIN</th>\n","      <th>Make</th>\n","      <th>Body_Style</th>\n","      <th>...</th>\n","      <th>Agency</th>\n","      <th>Violation_code</th>\n","      <th>Violation_Description</th>\n","      <th>Fine_amount</th>\n","      <th>Latitude</th>\n","      <th>Longitude</th>\n","      <th>Agency_Description</th>\n","      <th>Color_Description</th>\n","      <th>Body_Style_Description</th>\n","      <th>Unnamed:_0.1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1103341116</td>\n","      <td>12/21/2015</td>\n","      <td>1251.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>CA</td>\n","      <td>200304.0</td>\n","      <td>NaN</td>\n","      <td>HOND</td>\n","      <td>PA</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>4000A1</td>\n","      <td>NO EVIDENCE OF REG</td>\n","      <td>50.0</td>\n","      <td>99999.0</td>\n","      <td>99999.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1103700150</td>\n","      <td>12/21/2015</td>\n","      <td>1435.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>CA</td>\n","      <td>201512.0</td>\n","      <td>NaN</td>\n","      <td>GMC</td>\n","      <td>VN</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>4000A1</td>\n","      <td>NO EVIDENCE OF REG</td>\n","      <td>50.0</td>\n","      <td>99999.0</td>\n","      <td>99999.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1104803000</td>\n","      <td>12/21/2015</td>\n","      <td>2055.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>CA</td>\n","      <td>201503.0</td>\n","      <td>NaN</td>\n","      <td>NISS</td>\n","      <td>PA</td>\n","      <td>...</td>\n","      <td>2.0</td>\n","      <td>8939</td>\n","      <td>WHITE CURB</td>\n","      <td>58.0</td>\n","      <td>6439997.9</td>\n","      <td>1802686.4</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows × 23 columns</p>\n","</div>"],"text/plain":["  Ticket_number  Issue_Date  Issue_time Meter_Id  Marked_Time RP_State_Plate  \\\n","0    1103341116  12/21/2015      1251.0      NaN          NaN             CA   \n","1    1103700150  12/21/2015      1435.0      NaN          NaN             CA   \n","2    1104803000  12/21/2015      2055.0      NaN          NaN             CA   \n","\n","   Plate_Expiry_Date  VIN  Make Body_Style  ... Agency Violation_code  \\\n","0           200304.0  NaN  HOND         PA  ...    1.0         4000A1   \n","1           201512.0  NaN   GMC         VN  ...    1.0         4000A1   \n","2           201503.0  NaN  NISS         PA  ...    2.0           8939   \n","\n","  Violation_Description  Fine_amount   Latitude  Longitude  \\\n","0    NO EVIDENCE OF REG         50.0    99999.0    99999.0   \n","1    NO EVIDENCE OF REG         50.0    99999.0    99999.0   \n","2            WHITE CURB         58.0  6439997.9  1802686.4   \n","\n","   Agency_Description  Color_Description  Body_Style_Description  Unnamed:_0.1  \n","0                 NaN                NaN                     NaN           0.0  \n","1                 NaN                NaN                     NaN           1.0  \n","2                 NaN                NaN                     NaN           2.0  \n","\n","[3 rows x 23 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Confirm rename\n","df.head(3)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"6628b023-dac9-42f5-b173-ac6a39f021fd","showTitle":false,"title":""}},"source":["##### 3. Change data types for (Ticket_number, Issue_Date ) columns into (string, datetime) respectively"]},{"cell_type":"code","execution_count":6,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"0acf693e-00d4-4179-a42d-287a8bd71590","showTitle":false,"title":""}},"outputs":[{"data":{"text/plain":["Ticket_number              object\n","Issue_Date                 object\n","Issue_time                float64\n","Meter_Id                   object\n","Marked_Time               float64\n","RP_State_Plate             object\n","Plate_Expiry_Date         float64\n","VIN                       float64\n","Make                       object\n","Body_Style                 object\n","Color                      object\n","Location                   object\n","Route                      object\n","Agency                    float64\n","Violation_code             object\n","Violation_Description      object\n","Fine_amount               float64\n","Latitude                  float64\n","Longitude                 float64\n","Agency_Description        float64\n","Color_Description         float64\n","Body_Style_Description    float64\n","Unnamed:_0.1              float64\n","dtype: object"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.dtypes"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["120602    4280153150\n","53890     4279335970\n","71090     4277664941\n","163268    4282731445\n","105490    4279976385\n","47429     4274696274\n","21090     1106476372\n","149825    4280500652\n","37276     4277757061\n","17890     4278804353\n","165670    4280699113\n","136963    1112198290\n","77409     4279628544\n","129207    4282283762\n","14576     4278731041\n","97781     4278241925\n","4366      4278481513\n","38493     4274392205\n","94871     4275298064\n","82459     4281701082\n","37912     4279118863\n","110663    4282044686\n","94273     4281842574\n","134102    4275683543\n","136005    4276641563\n","25012     4277320036\n","77175     4279626201\n","43992     4277273906\n","103016    4281948451\n","20710     4275748735\n","80523     4274831050\n","25775     4278935614\n","97863     4281887245\n","101468    4274978396\n","93011     4279831382\n","59684     4281420220\n","74515     4274619005\n","119134    4280135996\n","126854    1109400703\n","36831     4279104141\n","58049     4276261754\n","139174    1112762814\n","25552     4278929885\n","66603     4274822941\n","131291    4282309710\n","100793    4276351796\n","25760     4274547513\n","38152     4277888090\n","128561    4274616964\n","96528     4281870692\n","Name: Ticket_number, dtype: object"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df['Ticket_number'].sample(50)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Unable to parse string \"1107495524D\" at position 456378","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: Unable to parse string \"1107495524D\"","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mC:\\Users\\JARED~1.GOD\\AppData\\Local\\Temp/ipykernel_29612/2623609475.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert  (Ticket_number, Issue_Date ) columns into (string, datetime) and confirm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Ticket_number'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Ticket_number'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Issue_Date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Issue_Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[0mcoerce_numeric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m             values, _ = lib.maybe_convert_numeric(\n\u001b[0m\u001b[0;32m    184\u001b[0m                 \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_numeric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             )\n","\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: Unable to parse string \"1107495524D\" at position 456378"]}],"source":["# Convert  (Ticket_number, Issue_Date ) columns into (string, datetime) and confirm\n","df['Ticket_number'] =df['Ticket_number'])\n","df['Issue_Date'] = pd.to_datetime(df['Issue_Date'])\n","df.dtypes"]},{"cell_type":"markdown","metadata":{},"source":["Error with a D as part of a ticket number - assume `D=0` like OCR issue - replace"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Ticket_number</th>\n","      <th>Issue_Date</th>\n","      <th>Issue_time</th>\n","      <th>Meter_Id</th>\n","      <th>Marked_Time</th>\n","      <th>RP_State_Plate</th>\n","      <th>Plate_Expiry_Date</th>\n","      <th>VIN</th>\n","      <th>Make</th>\n","      <th>Body_Style</th>\n","      <th>...</th>\n","      <th>Agency</th>\n","      <th>Violation_code</th>\n","      <th>Violation_Description</th>\n","      <th>Fine_amount</th>\n","      <th>Latitude</th>\n","      <th>Longitude</th>\n","      <th>Agency_Description</th>\n","      <th>Color_Description</th>\n","      <th>Body_Style_Description</th>\n","      <th>Unnamed:_0.1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","<p>0 rows × 23 columns</p>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [Ticket_number, Issue_Date, Issue_time, Meter_Id, Marked_Time, RP_State_Plate, Plate_Expiry_Date, VIN, Make, Body_Style, Color, Location, Route, Agency, Violation_code, Violation_Description, Fine_amount, Latitude, Longitude, Agency_Description, Color_Description, Body_Style_Description, Unnamed:_0.1]\n","Index: []\n","\n","[0 rows x 23 columns]"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["# Replace 1107495524D with 11074955240\n","\n","df[df['Ticket_number']=='1107495524D']"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# Replace value\n","\n","df['Ticket_number'] = df['Ticket_number'].replace(['1107495524D'],'11074955240', inplace = True)\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["df.replace(to_replace ='1107495524D',\n","           value ='11074955240',\n","           inplace=True)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Ticket_number</th>\n","      <th>Issue_Date</th>\n","      <th>Issue_time</th>\n","      <th>Meter_Id</th>\n","      <th>Marked_Time</th>\n","      <th>RP_State_Plate</th>\n","      <th>Plate_Expiry_Date</th>\n","      <th>VIN</th>\n","      <th>Make</th>\n","      <th>Body_Style</th>\n","      <th>...</th>\n","      <th>Agency</th>\n","      <th>Violation_code</th>\n","      <th>Violation_Description</th>\n","      <th>Fine_amount</th>\n","      <th>Latitude</th>\n","      <th>Longitude</th>\n","      <th>Agency_Description</th>\n","      <th>Color_Description</th>\n","      <th>Body_Style_Description</th>\n","      <th>Unnamed:_0.1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","<p>0 rows × 23 columns</p>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [Ticket_number, Issue_Date, Issue_time, Meter_Id, Marked_Time, RP_State_Plate, Plate_Expiry_Date, VIN, Make, Body_Style, Color, Location, Route, Agency, Violation_code, Violation_Description, Fine_amount, Latitude, Longitude, Agency_Description, Color_Description, Body_Style_Description, Unnamed:_0.1]\n","Index: []\n","\n","[0 rows x 23 columns]"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["# Confirm\n","\n","#df[df['Ticket_number']=='1107495524D']\n","\n","df[df['Ticket_number']=='11074955240']\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Unable to parse string \"1107495535D\" at position 456379","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: Unable to parse string \"1107495535D\"","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mC:\\Users\\JARED~1.GOD\\AppData\\Local\\Temp/ipykernel_29612/1948660623.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Re run datatype conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Ticket_number'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Ticket_number'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Issue_Date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Issue_Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[0mcoerce_numeric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m             values, _ = lib.maybe_convert_numeric(\n\u001b[0m\u001b[0;32m    184\u001b[0m                 \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_numeric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             )\n","\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: Unable to parse string \"1107495535D\" at position 456379"]}],"source":["# Re run datatype conversion\n","\n","df['Ticket_number'] =pd.to_numeric(df['Ticket_number'])\n","df['Issue_Date'] = pd.to_datetime(df['Issue_Date'])\n","df.dtypes"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"1ee22dfd-05ab-4a2b-8841-165965158354","showTitle":false,"title":""}},"source":["##### 4. Check if a column has any digits in its values. Return the rows where this is true. Check for column \"Violation_Description\". \n","e.g. 17104h --> True,     WHITE CURB --> False"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"8c7a6c77-702a-49fa-b8b6-103fb749af6c","showTitle":false,"title":""}},"outputs":[],"source":["my_col = 'Violation_Description'\n","\n","def has_digit(df, my_col):\n","    \n","    *** WRITE YOUR CODE TO complete the function ***\n","    \n","    return \n","\n","has_digit(df_pandas, my_col)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"6222d006-ef6f-46c1-b24e-5fb331d77731","showTitle":false,"title":""}},"source":["##### 5. Write a function to check if a column only has \"Alphabet\" values, return the rows where this is not true. Check for \"Make\" column."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9fff9512-f73d-4060-9f33-421f71a22c4a","showTitle":false,"title":""}},"outputs":[],"source":["my_col = 'Make'\n","\n","def only_alpha(df, my_col):\n","    \n","    *** WRITE YOUR CODE TO complete the function ***\n","    \n","    return \n","\n","only_alpha(df_pandas, my_col)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"4c0c9ba4-4cd4-421d-9cef-5bde72990866","showTitle":false,"title":""}},"source":["##### 6. Write a function to check if a column only has \"Numberic\" values, return the rows where this is not true. Check for TicketNumber column."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"62c7b641-1f9d-426a-ba90-875581f34921","showTitle":false,"title":""}},"outputs":[],"source":["my_col = 'Ticket_number'\n","\n","def only_number(df, my_col):\n","    \n","    *** WRITE YOUR CODE TO complete the function ***\n","    \n","    return \n","\n","only_number(df_pandas, my_col)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"2db6c35d-cfc8-486f-8f41-65a2f49d042a","showTitle":false,"title":""}},"source":["##### 7. Add a column \"Distance_to_pointA\", collecting the distance between each point and the point A: Ya= 6439997, Xa= 1802686. \n","Drop rows with either Nan or values like 99999. \n","\n","Note: Parking citations with latitude / longitude (XY) in US Feet coordinates according to the NAD_1983_StatePlane_California_V_FIPS_0405_Feet projection."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"c5bec144-bb95-4b6b-be93-aa2aff025b2c","showTitle":false,"title":""}},"outputs":[],"source":["# drop rows with values like 99999 in Latitude and/or Longitude\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"df243201-cac8-47d2-a012-f5d70ac961e5","showTitle":false,"title":""}},"outputs":[],"source":["# calculate distance between all rows(Longitude/Latitude) and point A (6439997,1802686)\n"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"77b64cff-1e9c-4150-abd1-82d4363fff05","showTitle":false,"title":""}},"source":["##### 8. Is there any duplicates in dataframe? If yes, print them and then drop them."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9ad0de0d-1d8b-42aa-a774-f9f982aedd04","showTitle":false,"title":""}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9f8a5f9f-b9d5-4208-bad9-7ede1d8fc4a7","showTitle":false,"title":""}},"source":["##### 9. Find the columns with more than 70% missing values, print them, and then drop them."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"4f73bc16-7a83-49b1-9ab3-d1295733c530","showTitle":false,"title":""}},"outputs":[],"source":["# Find the columns with more than 70% missing values\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"4f2c0343-c724-4845-a38e-ddd6b8d2ae04","showTitle":false,"title":""}},"outputs":[],"source":["# Drop columns with more than 70% missing values \n"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"2fba1e93-9fe4-49c7-8871-27bd0cc3a04f","showTitle":false,"title":""}},"source":["##### 10. Find RP_State_Plates that are not for US, then drop their data."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"65a584aa-d828-41be-8208-2089d3dd5798","showTitle":false,"title":""}},"outputs":[],"source":["# To find the US state abbrevation, you can use State_Abbreviation.xlsx' dataset\n"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"8cb7c587-5aea-4d2b-8678-4b7731fe97a8","showTitle":false,"title":""}},"source":["##### 11. Almost 4% of Fine_Amount column has missing values, handle these missing values."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"86c00653-5883-4c98-bb35-8877fec43228","showTitle":false,"title":""}},"outputs":[],"source":["# Use your knowledge to handle the missing values, you need to impute values based on useful information of other columns \n"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"c86273d1-392d-4da7-9ac8-ddc7339e7a32","showTitle":false,"title":""}},"source":["##### 12. Split the \"Location\" column into new columns using SPACE as delimiter. You may need to write a function. The final splitted data should be structured like below (the number of columns may be different):\n","![address_columns.PNG](attachment:address_columns.PNG)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d936b40d-3f1b-480c-9d18-ce1301a3d987","showTitle":false,"title":""}},"outputs":[],"source":["def address_sep(df_pandas):\n"," \n","    *** WRITE YOUR CODE TO complete the function ***\n","    return df_pandas\n","\n","df_pandas = address_sep(df_pandas)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"181ba8dd-fb02-4540-96c4-14589fb8f8ed","showTitle":false,"title":""}},"source":["##### 13. Extract the \"Issue_year\" of  \"Issue_Date\" column and save it as a new column \"Issue_year\" as an integer type."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"5d0a0132-fe94-4645-8551-4916ca93a8bf","showTitle":false,"title":""}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"277e2217-179b-4ae8-9d06-9e79449c4f1d","showTitle":false,"title":""}},"source":["##### 14. Write the pandas dataframe into a Parquet file (cleaned_parking_citations) partition by \"Year\" column."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"c9b7758c-7a68-4f4a-8e37-1b045a30859e","showTitle":false,"title":""}},"outputs":[],"source":["df_pandas.to_parquet(*** WRITE YOUR CODE TO complete the function ***)"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"Data_Engineering_Exercise_1","notebookOrigID":2073302174308515,"widgets":{}},"interpreter":{"hash":"ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
